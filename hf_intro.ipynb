{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a09e1-c0d3-4b18-8232-5443f6100a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45c646-aac1-4b52-bee6-12a602f12d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9434db18-eb6a-47c4-98bd-5e7a7ad231f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10857f9208944c4b550a99fc88a31c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login, logout\n",
    "login()\n",
    "# Should see this:\n",
    "# Token is valid (permission: write).\n",
    "# Your token has been saved in your configured git credential helpers (manager).\n",
    "# Your token has been saved to C:\\Users\\Owner\\.cache\\huggingface\\token\n",
    "# Login successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ba416a-8294-40af-bea9-1ee9f8f451fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following along with the Datacamp tutorial here:\n",
    "# https://www.datacamp.com/datalab/w/be6d48e3-3eb3-417c-8787-595d0636535e/edit\n",
    "import os\n",
    "import torch\n",
    "import huggingface_hub as hf_hub\n",
    "import datasets\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5250129d-b9dd-4b0f-b3bc-f94d50bd4864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5abebf67224302bd1615a91cb6a92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\VirtualEnvironments\\datacamp\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Owner\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-emoji. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1e17fef01d4bc0b2826b98516f322e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4c4b2355d74b4db88e7ccdd5380e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f06a8460674473ab2fbd5ab2c65286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaTokenizerFast(name_or_path='cardiffnlp/twitter-roberta-base-emoji', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emoji\")\n",
    "# Print the tokenizer to see the data preprocessing configuration for this model \n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cdcd5f-baf5-436d-b9d8-a76cddf21a9d",
   "metadata": {},
   "source": [
    "## What from_pretrained() does\n",
    "\n",
    "The from_pretrained() method (see [docs](https//huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.from_pretrained)) first searches for a model repository with the same name on the Hugging Face Hub but it also accepts a local path or a URL with the expected folder structure. You can simply git clone the repository and load it from your local path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da26cf-5969-49e6-a7ee-c21ec8ac79e0",
   "metadata": {},
   "source": [
    "## Tokenizers\n",
    "\n",
    "NLP models can't process text inputs as it is and need to be converted to a fixed length mathematical format. The Tokenizer classes preprocess the text such that each word and punctuation is given a unique ID or a token, short sentences are padded and long sentences are truncated to create fixed-size input vectors. They also allow using additional tokens such as bos, eos, unk, sep, and more to specify start and end of sentences, and to assign token IDS to unknown words that are not in the tokenizer vocabulary.\n",
    "\n",
    "The output of the tokenizer tells us this pretrained model uses a tokenizer with a 50265 unique token IDs that applies padding or truncation to the end of each input text, and removes leading (leftside) extra whitespaces. You can always refer to the corresponding Tokenizer docs\n",
    "to learn more about each preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb05760-cd5b-44d1-867c-c8438dc91908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fe9c41ada246538e6a968683a966b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-emoji and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained \"cardiffnlp/twitter-roberta-base-emoji\" model\n",
    "model = AutoModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-emoji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c0d71-186b-4a04-a591-df376f62156e",
   "metadata": {},
   "source": [
    "## Notes on Model Loading\n",
    "\n",
    "Take a look at the warning above. We were only able to load a chunk of the model parameters included in the checkpoint with the AutoModel class.\n",
    "\n",
    "This is because all transformers models are designed to have a single base class and multiple task-specific prediction classes built on top of it. The AutoModel class is designed to only load the base model parameters such as `RobertaModel` but not task-specific models such as `RobertaForSequenceClassification`.\n",
    "\n",
    "In order to identify the exact class name and task of your target checkpoint, you can simply refer to the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534340f-59f0-41c3-8261-73ab7f787f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c2467-2278-4b3c-81e4-290e0140ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44210d87-ba14-4006-bec4-75c6247323fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a84538-3d70-4a55-9250-2d0165112630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24b709-a735-40ea-a327-caa5fd0c8537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efc391-64e1-4e47-a929-a89d989eee2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f3c13-9478-4251-8777-4a31e9e4d8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde5c4f-1a8b-458c-a305-1ab081c04897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75add37-a2e4-4e12-98fe-3c51da85ac40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef48a6f-3a17-458e-92d3-5156d5b1ce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c3322-0b72-40e0-ac68-ba46fd957702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e280d-b90c-419f-b337-e42f8a5df62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
